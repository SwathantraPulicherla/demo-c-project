name: AI Test Execution

on:
  issues:
    types: [opened, labeled, edited]
  workflow_dispatch:  # Manual trigger for testing

# Allow GitHub Pages deployment
permissions:
  contents: write  # Added write permission for committing reports
  pages: write
  id-token: write

# Allow one concurrent deployment
concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  run-tests:
    if: contains(github.event.issue.labels.*.name, 'ai-test-run') || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    outputs:
      coverage_available: ${{ steps.test-summary.outputs.coverage_available }}

    steps:
    - name: Checkout target repository
      uses: actions/checkout@v4
      with:
        path: target-repo

    - name: Checkout AI tools
      uses: actions/checkout@v4
      with:
        repository: SwathantraPulicherla/ai-test-runner
        path: ai-tools
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Checkout AI test generator
      uses: actions/checkout@v4
      with:
        repository: SwathantraPulicherla/ai-c-test-generator
        path: ai-test-generator
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Upgrade pip and setuptools
      run: |
        python -m pip install --upgrade pip setuptools wheel

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y cmake build-essential lcov

    - name: Install AI test runner
      run: |
        cd ai-tools
        pip install -e .
        # Set PYTHONPATH to include ai-test-generator for imports
        echo "PYTHONPATH=$GITHUB_WORKSPACE/ai-test-generator:$PYTHONPATH" >> $GITHUB_ENV

    - name: Run AI tests
      id: test-execution
      run: |
        cd target-repo
        # Clean build directory to avoid CMake cache conflicts
        rm -rf build/
        ai-test-runner --verbose

    - name: Generate test summary
      id: test-summary
      run: |
        cd target-repo
        # Extract test results from the output
        if [ -d "tests/tests_reports" ]; then
          TEST_SUMMARY=$(find tests/tests_reports -name "*.txt" -exec cat {} \; | grep -E "(PASSED|FAILED|Individual Tests)" | tail -10)
          echo "summary<<EOF" >> $GITHUB_OUTPUT
          echo "$TEST_SUMMARY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
        else
          echo "summary=No test reports found" >> $GITHUB_OUTPUT
        fi
        
        # Check for coverage report
        if [ -d "tests/coverage_reports" ]; then
          echo "coverage_available=true" >> $GITHUB_OUTPUT
        else
          echo "coverage_available=false" >> $GITHUB_OUTPUT
        fi

    - name: Commit test and coverage reports to repository
      if: success()
      run: |
        cd target-repo
        
        # Configure git
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Check if there are any changes to commit
        if [ -d "tests/tests_reports" ] || [ -d "tests/coverage_reports" ]; then
          # Add the generated reports
          git add tests/tests_reports/ tests/coverage_reports/ 2>/dev/null || true
          
          # Check if there are staged changes
          if git diff --staged --quiet; then
            echo "No new reports to commit"
          else
            # Commit the reports
            git commit -m "ðŸ¤– AI Test Results: Add latest test and coverage reports
            
            - Test reports: $(find tests/tests_reports -name "*.txt" 2>/dev/null | wc -l) files
            - Coverage reports: $(find tests/coverage_reports -name "*.html" 2>/dev/null | wc -l) files
            
            Generated by AI Test Runner on $(date -u +'%Y-%m-%d %H:%M:%S UTC')" || echo "No changes to commit"
            
            # Push the commit back to the repository
            git push origin HEAD:${{ github.ref_name }} || echo "Failed to push reports (this may be normal for PRs)"
          fi
        else
          echo "No reports directories found to commit"
        fi

    - name: Comment test results on issue
      if: github.event_name == 'issues'
      uses: actions/github-script@v7
      with:
        script: |
          const testExitCode = ${{ steps.test-execution.outcome == 'success' }};
          const testSummary = `${{ steps.test-summary.outputs.summary }}`;
          const coverageAvailable = `${{ steps.test-summary.outputs.coverage_available }}`;

          let body;
          if (testExitCode) {
            body = `âœ… **AI Test Execution Completed Successfully!**\n\n## Test Results\n\`\`\`\n${testSummary}\n\`\`\`\n\nAll tests passed! ðŸŽ‰`;
          } else {
            body = `âŒ **AI Test Execution Completed with Failures**\n\n## Test Results\n\`\`\`\n${testSummary}\n\`\`\`\n\nSome tests failed. Please check the detailed test reports in the \`tests/tests_reports/\` directory.`;
          }
          
          if (coverageAvailable === 'true') {
            body += `\n\n## Coverage Report\nðŸ“Š Coverage reports are available:\n- **GitHub Pages**: https://${context.repo.owner}.github.io/${context.repo.repo}/\n- **Download Artifact**: Download the "coverage-reports" artifact to view detailed code coverage information.`;
          }

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });

    - name: Upload test reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-reports
        path: target-repo/tests/test_reports/
        retention-days: 30

    - name: Upload coverage reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: coverage-reports
        path: target-repo/tests/coverage_reports/
        retention-days: 30

  # Deploy coverage reports to GitHub Pages
  deploy-coverage:
    if: always() && needs.run-tests.outputs.coverage_available == 'true'
    needs: run-tests
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
    - name: Checkout target repository
      uses: actions/checkout@v4
      with:
        path: target-repo

    - name: Checkout AI tools
      uses: actions/checkout@v4
      with:
        repository: SwathantraPulicherla/ai-test-runner
        path: ai-tools
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Checkout AI test generator
      uses: actions/checkout@v4
      with:
        repository: SwathantraPulicherla/ai-c-test-generator
        path: ai-test-generator
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Upgrade pip and setuptools
      run: |
        python -m pip install --upgrade pip setuptools wheel

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y cmake build-essential lcov

    - name: Install AI test runner
      run: |
        cd ai-tools
        pip install -e .
        # Set PYTHONPATH to include ai-test-generator for imports
        echo "PYTHONPATH=$GITHUB_WORKSPACE/ai-test-generator:$PYTHONPATH" >> $GITHUB_ENV

    - name: Generate coverage reports
      run: |
        cd target-repo
        # Clean build directory to avoid CMake cache conflicts
        rm -rf build/
        ai-test-runner --verbose

    - name: Upload coverage report artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: target-repo/tests/coverage_reports/  # must match the folder with your HTML report

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4